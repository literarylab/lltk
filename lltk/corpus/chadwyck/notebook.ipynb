{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chadwyck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lltk\n",
    "C=lltk.load('Chadwyck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 17:03:33 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:03:33 INFO: Use device: cpu\n",
      "2020-12-15 17:03:33 INFO: Loading: tokenize\n",
      "2020-12-15 17:03:33 INFO: Loading: pos\n",
      "2020-12-15 17:03:37 INFO: Loading: lemma\n",
      "2020-12-15 17:03:37 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:03:37 INFO: Use device: cpu\n",
      "2020-12-15 17:03:37 INFO: Loading: tokenize\n",
      "2020-12-15 17:03:37 INFO: Loading: pos\n",
      "2020-12-15 17:03:37 INFO: Loading: depparse\n",
      "2020-12-15 17:03:37 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:03:37 INFO: Use device: cpu\n",
      "2020-12-15 17:03:37 INFO: Loading: tokenize\n",
      "2020-12-15 17:03:37 INFO: Loading: pos\n",
      "2020-12-15 17:03:38 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:03:38 INFO: Use device: cpu\n",
      "2020-12-15 17:03:38 INFO: Loading: tokenize\n",
      "2020-12-15 17:03:38 INFO: Loading: pos\n",
      "2020-12-15 17:03:38 INFO: Loading: lemma\n",
      "2020-12-15 17:03:38 INFO: Loading: depparse\n",
      "2020-12-15 17:03:39 INFO: Done loading processors!\n",
      "2020-12-15 17:03:39 INFO: Loading: lemma\n",
      "2020-12-15 17:03:40 INFO: Loading: depparse\n",
      "2020-12-15 17:03:40 INFO: Loading: lemma\n",
      "2020-12-15 17:03:40 INFO: Loading: depparse\n",
      "2020-12-15 17:03:41 INFO: Done loading processors!\n",
      "2020-12-15 17:03:43 INFO: Done loading processors!\n",
      "2020-12-15 17:03:43 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# C.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.gen_freqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing sentences with stanza (nproc=4):   0%|          | 0/61067 [00:00<?, ?it/s]2020-12-15 17:01:29 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:01:29 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:01:29 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:01:29 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-12-15 17:01:29 INFO: Use device: cpu\n",
      "2020-12-15 17:01:29 INFO: Use device: cpu\n",
      "2020-12-15 17:01:29 INFO: Use device: cpu\n",
      "2020-12-15 17:01:29 INFO: Loading: tokenize\n",
      "2020-12-15 17:01:29 INFO: Loading: tokenize\n",
      "2020-12-15 17:01:29 INFO: Use device: cpu\n",
      "2020-12-15 17:01:29 INFO: Loading: tokenize\n",
      "2020-12-15 17:01:29 INFO: Loading: tokenize\n",
      "2020-12-15 17:01:29 INFO: Loading: pos\n",
      "2020-12-15 17:01:29 INFO: Loading: pos\n",
      "2020-12-15 17:01:29 INFO: Loading: pos\n",
      "2020-12-15 17:01:29 INFO: Loading: pos\n",
      "2020-12-15 17:01:31 INFO: Loading: lemma\n",
      "2020-12-15 17:01:32 INFO: Loading: lemma\n",
      "2020-12-15 17:01:32 INFO: Loading: lemma\n",
      "2020-12-15 17:01:32 INFO: Loading: lemma\n",
      "2020-12-15 17:01:32 INFO: Loading: depparse\n",
      "2020-12-15 17:01:32 INFO: Loading: depparse\n",
      "2020-12-15 17:01:32 INFO: Loading: depparse\n",
      "2020-12-15 17:01:32 INFO: Loading: depparse\n",
      "2020-12-15 17:01:35 INFO: Done loading processors!\n",
      "2020-12-15 17:01:35 INFO: Done loading processors!\n",
      "2020-12-15 17:01:35 INFO: Done loading processors!\n",
      "2020-12-15 17:01:35 INFO: Done loading processors!\n",
      "Parsing sentences with stanza (nproc=4):   0%|          | 1/61067 [02:03<2094:01:00, 123.45s/it]Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ryan/github/lltk/lltk/model/corenlp.py\", line 18, in parse\n",
      "    para_obj = nlp(para)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-05fc3052486d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_stanza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/lltk/lltk/corpus/corpus.py\u001b[0m in \u001b[0;36mgen_stanza\u001b[0;34m(self, num_proc)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths_txt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Parsing sentences with stanza'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/lltk/lltk/tools/tools.py\u001b[0m in \u001b[0;36mpmap\u001b[0;34m(*x, **y)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \"\"\"\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# return as list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmap_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/lltk/lltk/tools/tools.py\u001b[0m in \u001b[0;36mpmap_iter\u001b[0;34m(func, objs, num_proc, use_threads, desc)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# yield iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 166, in __call__\n",
      "    doc = self.process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 160, in process\n",
      "    doc = self.processors[processor_name].process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/depparse_processor.py\", line 42, in process\n",
      "    preds += self.trainer.predict(b)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/trainer.py\", line 74, in predict\n",
      "    _, preds = self.model(word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/model.py\", line 133, in forward\n",
      "    lstm_outputs, _ = self.parserlstm(lstm_inputs, sentlens, hx=(self.parserlstm_h_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous(), self.parserlstm_c_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous()))\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/hlstm.py\", line 104, in forward\n",
      "    h, (ht, ct) = self.lstm[l](input, seqlens, layer_hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/packed_lstm.py\", line 22, in forward\n",
      "    res = self.lstm(input, hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 580, in forward\n",
      "    self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ryan/github/lltk/lltk/model/corenlp.py\", line 18, in parse\n",
      "    para_obj = nlp(para)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 166, in __call__\n",
      "    doc = self.process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 160, in process\n",
      "    doc = self.processors[processor_name].process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/depparse_processor.py\", line 42, in process\n",
      "    preds += self.trainer.predict(b)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/trainer.py\", line 74, in predict\n",
      "    _, preds = self.model(word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/model.py\", line 133, in forward\n",
      "    lstm_outputs, _ = self.parserlstm(lstm_inputs, sentlens, hx=(self.parserlstm_h_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous(), self.parserlstm_c_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous()))\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/hlstm.py\", line 104, in forward\n",
      "    h, (ht, ct) = self.lstm[l](input, seqlens, layer_hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/packed_lstm.py\", line 22, in forward\n",
      "    res = self.lstm(input, hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 580, in forward\n",
      "    self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ryan/github/lltk/lltk/model/corenlp.py\", line 18, in parse\n",
      "    para_obj = nlp(para)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 166, in __call__\n",
      "    doc = self.process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 160, in process\n",
      "    doc = self.processors[processor_name].process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/depparse_processor.py\", line 42, in process\n",
      "    preds += self.trainer.predict(b)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/trainer.py\", line 74, in predict\n",
      "    _, preds = self.model(word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/model.py\", line 133, in forward\n",
      "    lstm_outputs, _ = self.parserlstm(lstm_inputs, sentlens, hx=(self.parserlstm_h_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous(), self.parserlstm_c_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous()))\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/hlstm.py\", line 104, in forward\n",
      "    h, (ht, ct) = self.lstm[l](input, seqlens, layer_hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/packed_lstm.py\", line 22, in forward\n",
      "    res = self.lstm(input, hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 580, in forward\n",
      "    self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ryan/github/lltk/lltk/model/corenlp.py\", line 18, in parse\n",
      "    para_obj = nlp(para)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 166, in __call__\n",
      "    doc = self.process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/core.py\", line 160, in process\n",
      "    doc = self.processors[processor_name].process(doc)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/pipeline/depparse_processor.py\", line 42, in process\n",
      "    preds += self.trainer.predict(b)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/trainer.py\", line 74, in predict\n",
      "    _, preds = self.model(word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/depparse/model.py\", line 133, in forward\n",
      "    lstm_outputs, _ = self.parserlstm(lstm_inputs, sentlens, hx=(self.parserlstm_h_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous(), self.parserlstm_c_init.expand(2 * self.args['num_layers'], word.size(0), self.args['hidden_dim']).contiguous()))\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/hlstm.py\", line 104, in forward\n",
      "    h, (ht, ct) = self.lstm[l](input, seqlens, layer_hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/stanza/models/common/packed_lstm.py\", line 22, in forward\n",
      "    res = self.lstm(input, hx)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 580, in forward\n",
      "    self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "C.gen_stanza()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
